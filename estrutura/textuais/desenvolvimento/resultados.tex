\chapter{RESULTADOS}
\label{chap:results}

Este capítulo é dedicado aos resultados obtidos com testes
feitos utilizando a solução desenvolvida no trabalho. Os testes
utilizaram um ambiente de VM para que os testes possam ser reproduzidos 
mais fácilmente. Foram utilizadas diferentes métricas para avaliar
o comportamento da API. Além das diferentes métricas, os dados inseridos 
também possuem diferentes formatos e valores. Isso foi feito para que 
seja percebido o comportamento da API em diferentes cenários, assim como
avaliar se o comportamento é alterado drásticamente ou mantem seu comportamento
mesmo em casos extremos.

É importante definir bem como a API se comporta em cenários diferentes, pois,
dependendo aonde a mesma estiver instalada, cada requisição gera um custo e este custo 
deve ser conhecido. Por exemplo, se a API estiver hospedada em nuvem, cada requisição tem 
um custo, seja ele por tráfego de rede, armazenamento dos dados, processamento, etc. 
As métricas utilizadas buscam auxiliar na decisão de utilização da API.

Os testes realizados foram aplicados somente no recurso de otimizações,
que é a seleção de \textit{hosts}. Apesar da API ter outros recursos, como o de políticas,
este recurso é apenas um suporte para flexibilizar o uso das migrações. O problema 
que o trabalho se propõe a resolver envolve somente a etapa de criação de uma
otimização. Sendo assim, este é o cenário que é avaliado.

\section{AMBIENTE}

O ambiente utilizado foi uma máquina virtual utilizando \textbf{Ubuntu Server 18.04}
com memória de \textbf{4.0GB} utilizando um processador \textbf{2,3 GHz Intel Core i5}. 
As requisições são feitas através de uma rede \textit{bridge} da máquina física para a virtual.

A escolha de um ambiente com VM é permitir o isolamento de recursos. Além disso,
o ambiente é mantido de forma mais controlada, sendo assim, há uma melhor 
consistencia dos testes feitos. Além do maior controle sobre o ambiente, é importante salientar 
que o ambiente simulado está disponível nas nuvens comerciais na indústria, como AWS, AZURE e 
etc. Sendo assim, caso uma máquina com as características da VM testada for utilizada, 
o desempenho da API tende a ser o mesmo.

\section{DADOS UTILIZADOS}
A API do OptVM permite que seja feitas várias combinações de dados. As combinações
podem variar em relação à restrições utilizadas, objetivos da otimização, quantidade
de hosts, nuvens e datacenters envolvidos, entre outros. 

Na avaliação dos resultados, foram utilizados dados que simulam casos simples (utilizando poucos
hosts, restrições e objetivos) e casos mais complexos (utilizando mais hosts, restrições e objetivos). 
O formato dos cenários utilizados é demonstrado na Tabela \ref{tab:testdata-info}

\input{dados/tabelas/testdata-info.tex}

Os dados utilizados foram gerados através de um código java. O código
construído gerou em todos os casos 5 nuvens, sendo que, a quantidade de
datacenters/hosts varia para ficar compatível com cada cenário. Para cada
host, atribuiu-se 5 VMs.

Para os testes conter os dados mais próximos da realidade quanto possível,
foram pré-definidos alguns valores para atributos que são fixos, por exemplo,
sistema operacional, memória RAM total, armazenamento total. Nestes casos, um dos valores
pré-definidos foi selecionado aleatoriamente como valor para o atributo da entidade. 
Nos casos onde o atributo é completamente variável, foi atribuido valores aleatórios para os 
mesmos mantendo um intervalo condizente com a realidade, por exemplo, preço por armazenamento
entre 0.1 e 1 (centavos).

Como o OptVM permite escolher o tamanho do subconjunto de \textit{hosts} que quer obter,
além dos dados da nuvem, DCs e hosts, foi utilizado como padrão a busca de um subconjunto de
3 hosts como sendo uma possível solução. 

\section{MÉTRICAS UTILIZADAS}
É muito comum uma API ser medida através de uma medida quantitativa de requisições 
por segundo (RPS) que ela consegue atender. O número de requisições 
varia de aplicação para aplicação, e isso depende da tecnologia utilizada, 
arquitetura do sistema, se há consulta em banco de dados ou não, algoritmos utilizado, etc.
Esta métrica define se a utilização de um serviço é viável em relação a quantidade de consumidores ou
quantidade de utilização, ou seja, se atende as necessidades de uso do consumidor do serviço. 
Através desta métrica é possível identificar gargalos na utilização.

Além da métrica de requisições por segundo, outro aspecto importante na utilização de API
é o tamanho do \textit{payload}. O payload, muitas vezes é atribuido um custo por 
tráfego da máquina, e por processamento e armazenamento, sendo assim, quanto maior
o payload, mais tráfego, processamento e armazenamento ele gerará, consequentemente,
aumentará o custo. Esta métrica pode identificar possíveis erros em relação 
ao modelamento da API, ou seja, a API modelada de uma maneira mais otimizada, utilizando os dados
de maneira diferente, pode obter um \textit{payload} menor.

\subsection{WRK}

O WRK é uma ferramenta construída em C utilizada para fazer \textit{benchmarking} de 
aplicações HTTP. Com ela é possível fazer requisições concorrentes utilizando 
múltiplos ou um único core. Além disso, o WRK permite utilizar uma duração
do teste, threads e conexões HTTP. 

O resultado de um teste utilizando o WRK consegue nos trazer algumas informações 
sobre a API, como RPS, transferência por segundo, entre outras. Das informações que
o WRK nos traz, as escolhidas e o seu respectivo motivo foram:

\begin{enumerate}
  \item RPS: Medir a velocidade do serviço;
  \item Respostas com status de insucesso: Medir a confiabilidade. 
\end{enumerate}

Para o teste, foram utilizados os seguintes valores para os parâmetros do WRK:

\begin{enumerate}
  \item Conexões: 25
  \item Threads: 1
  \item Tempo de teste: 3 minutos
\end{enumerate}

Os parâmetros escolhidos para a realização dos testes, significam que uma thread está disparando requisições através 
de 25 conexões para o serviço ou seja, o serviço recebe as requisições através de 25 conexões
concorrentes. Já o tempo escolhido, foi de três minutos, para que não haja um viés no número
de requisições por conta de alguma lentidão inicial, por exemplo, pela abertura de conexão com 
banco de dados.

Além das métricas do WRK e o tamanho do payload, o OptVM salva o tempo de execução de cada
etapa da criação de uma otimização, que são, a aplicação das constraints e MOO. 
Por ser a fase mais significativa, na avaliação dos resultados quantitativos, foi considerada a média de tempo
de execução da MOO. A esta métrica foi dado o nome de \textit{optimization execution time}(OET).
Esta métrica permite identificarmos o impacto da fase de MOO na requisição.

\section{COMPARAÇÕES}

Nesta seção são apresentados os comparativos entre os cenários testados, utilizando os dados, 
métricas e ambiente descritos nas seções anteriores. 

Para as métricas, os seguintes resultados foram obtidos:

\input{dados/tabelas/results.tex}

A partir destes resultados algumas conclusões podem ser tiradas:

\begin{enumerate}
  \item Quando a requisição fica maior, eventuais erros começam a ocorrer;
  \item A quantidade de RPS diminui significativamente por causa do tamanho do \textit{payload};
  \item A fase de MOO não é afetada drasticamente, apesar do significativo aumento de \textit{hosts}.
\end{enumerate}

Quando comparado ao número de requisições de outros \textit{webservices}, a quantidade de RPS
é relativamente baixa. Porém, para o propósito deste \textit{webservice} a quantidade pode ser
suficiente, pois, como a migração é um evento custoso computacionalmente, o ideal é evitá-la.

Um dos diferenciais do OptVM é a flexibilidade que ele dá ao usuário da API para configurar
a otimização da maneira que melhor se adequar ao seu problema, através das políticas e de 
parâmetros. Tanto um usuário do \textit{webservice} que gerencie um ambiente complexo,
quanto um que gerencie um ambiente simples, podem obter vantagens o utilizando.